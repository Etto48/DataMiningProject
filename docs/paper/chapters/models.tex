\section{Models}
\label{sec:models}
Three different categories of models were
considered:
\begin{itemize}
    \item \textit{Decision Trees}
    \item \textit{Random Forests}
    \item \textit{Neural Networks}
    \begin{itemize}
        \item \textit{Feedforward Networks}
        \item \textit{LSTM Networks}
    \end{itemize}
\end{itemize}
Decision Trees and Random Forests both use
the BoW preprocessing with \textbf{binary} 
encoding.
Feedforward Neural Networks use the BoW
preprocessing with \textbf{TFIDF} encoding.
LSTM Networks were tested with both the
WE and GE preprocessing.

\subsection{Imbalanced Dataset}
To handle the imbalanced dataset, a class
weight was assigned to each class. The weight
for a class $c$ was calculated as
$W_c=\frac{|D|}{|C||D_c|}$ where $|D|$ is
the size of the dataset, $|C|$ is the number
of classes and $|D_c|$ is the number of
samples in class $c$. This weight was used in
the criterion of the Decision Trees and Random
Forests models, and in the loss function of
the Neural Networks models.

\subsection{Model Selection}
To find a good hyperparameter configuration
for each model, a random search was performed.
The search was done with 10 iterations for
each model (Decision Trees, Random Forests 
and Neural Networks). Each configuration was
evaluated with a 6-fold cross-validation on
the training set. Two subsequent random
searches were performed, the second one
narrowing the search space around the best
configuration found in the first search.
The search spaces for each model are shown
in \autoref{tab:hyperparameters_decision_tree_0}, 
\autoref{tab:hyperparameters_random_forest_0} and 
\autoref{tab:hyperparameters_neural_network_0} for the 
first search, and in 
\autoref{tab:hyperparameters_decision_tree_1},
\autoref{tab:hyperparameters_random_forest_1} and
\autoref{tab:hyperparameters_neural_network_1} for the
second search.

\input{tables/hypers}

Accuracy was used as the metric to evaluate
the models and we can see the results in
\autoref{fig:model_selection}.

\end{multicols}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/model_selection.png}
    \caption{Accuracy distribution of each model configuration tested during the model selection process.}
    \label{fig:model_selection}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/accuracy_distribution.png}
    \caption{Accuracy distribution of each model category.}
    \label{fig:accuracy_distribution}
\end{figure}
\begin{multicols}{2}

The best model was selected based on 
the average accuracy obtained in the
cross-validation. The accuracy distribution
of this model was compared to the other
models with a Wilcoxon signed-rank test,
some models were not significantly different 
($p>0.05$) from the best model and they 
are listed in \autoref{tab:best_models}.

\input{tables/best_models}